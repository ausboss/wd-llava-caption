Run the server.py then the notebook

make sure you have ollama and the following model
`ollama run llava:34b-v1.6-q4_K_M`
